using AudioRecorder.Core.Models;
using AudioRecorder.Core.Services;
using AudioRecorder.Services.Logging;
using NAudio.CoreAudioApi;
using NAudio.Wave;
using NAudio.Wave.SampleProviders;
using System.Diagnostics;

namespace AudioRecorder.Services.Audio;

/// <summary>
/// –ù–∞–¥—ë–∂–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ WASAPI.
/// –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π.
/// </summary>
public class WasapiAudioCaptureService : IAudioCaptureService, IDisposable
{
    private readonly object _lock = new();
    private readonly List<IWaveIn> _captures = new();
    private readonly List<BufferedWaveProvider> _buffers = new();
    private WaveFileWriter? _writer;
    private MixingSampleProvider? _mixer;
    private Thread? _recordingThread;
    private CancellationTokenSource? _cts;
    private readonly Stopwatch _stopwatch = new();
    private RecordingInfo _currentInfo;
    private volatile bool _isPaused;

    // –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç: 48kHz, 16-bit, stereo (—Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ)
    private readonly WaveFormat _outputFormat = new(48000, 16, 2);

    public event EventHandler<RecordingInfo>? RecordingStateChanged;

    public WasapiAudioCaptureService()
    {
        _currentInfo = new RecordingInfo(RecordingState.Stopped, TimeSpan.Zero, 0);
    }

    public Task<IReadOnlyList<AudioSource>> GetAvailableSourcesAsync()
    {
        return Task.Run(() =>
        {
            var sources = new List<AudioSource>();

            try
            {
                using var enumerator = new MMDeviceEnumerator();

                // –ü–æ–ª—É—á–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤—ã–≤–æ–¥–∞ (–¥–ª—è loopback)
                var defaultRender = GetDefaultDeviceSafe(enumerator, DataFlow.Render, Role.Multimedia);
                foreach (var device in enumerator.EnumerateAudioEndPoints(DataFlow.Render, DeviceState.Active))
                {
                    sources.Add(new AudioSource(
                        Id: device.ID,
                        Name: $"üîä {device.FriendlyName}",
                        Type: AudioSourceType.SystemOutput,
                        IsDefault: defaultRender != null && device.ID == defaultRender.ID
                    ));
                }

                // –ü–æ–ª—É—á–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –≤–≤–æ–¥–∞ (–º–∏–∫—Ä–æ—Ñ–æ–Ω—ã)
                var defaultCapture = GetDefaultDeviceSafe(enumerator, DataFlow.Capture, Role.Communications);
                foreach (var device in enumerator.EnumerateAudioEndPoints(DataFlow.Capture, DeviceState.Active))
                {
                    sources.Add(new AudioSource(
                        Id: device.ID,
                        Name: $"üé§ {device.FriendlyName}",
                        Type: AudioSourceType.Microphone,
                        IsDefault: defaultCapture != null && device.ID == defaultCapture.ID
                    ));
                }
            }
            catch (Exception ex)
            {
                AppLogger.LogError($"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {ex.Message}");
            }

            return (IReadOnlyList<AudioSource>)sources;
        });
    }

    private static MMDevice? GetDefaultDeviceSafe(MMDeviceEnumerator enumerator, DataFlow flow, Role role)
    {
        try
        {
            return enumerator.GetDefaultAudioEndpoint(flow, role);
        }
        catch
        {
            return null;
        }
    }

    public Task StartRecordingAsync(IReadOnlyList<AudioSource> sources, string outputPath)
    {
        if (sources.Count == 0)
            throw new ArgumentException("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ –∞—É–¥–∏–æ");

        if (_currentInfo.State != RecordingState.Stopped)
            throw new InvalidOperationException("–ó–∞–ø–∏—Å—å —É–∂–µ –∏–¥—ë—Ç");

        return Task.Run(() =>
        {
            lock (_lock)
            {
                try
                {
                    InitializeCapture(sources, outputPath);
                    StartCapture();
                    AppLogger.LogInfo($"–ó–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞: {sources.Count} –∏—Å—Ç–æ—á–Ω–∏–∫(–æ–≤) ‚Üí {outputPath}");
                }
                catch (Exception ex)
                {
                    AppLogger.LogError($"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏: {ex.Message}");
                    Cleanup();
                    throw;
                }
            }
        });
    }

    private void InitializeCapture(IReadOnlyList<AudioSource> sources, string outputPath)
    {
        using var enumerator = new MMDeviceEnumerator();

        // –§–æ—Ä–º–∞—Ç –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è (float, stereo)
        var mixFormat = WaveFormat.CreateIeeeFloatWaveFormat(_outputFormat.SampleRate, 2);
        _mixer = new MixingSampleProvider(mixFormat) { ReadFully = true };

        foreach (var source in sources)
        {
            try
            {
                var device = enumerator.GetDevice(source.Id);
                IWaveIn capture = source.Type == AudioSourceType.SystemOutput
                    ? new WasapiLoopbackCapture(device)
                    : new WasapiCapture(device);

                // –ë—É—Ñ–µ—Ä –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç —ç—Ç–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                var buffer = new BufferedWaveProvider(capture.WaveFormat)
                {
                    BufferLength = capture.WaveFormat.AverageBytesPerSecond * 5, // 5 —Å–µ–∫ –±—É—Ñ–µ—Ä
                    DiscardOnBufferOverflow = true,
                    ReadFully = true
                };

                // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –º–∏–∫—à–µ—Ä–∞
                ISampleProvider sampleProvider = buffer.ToSampleProvider();

                // –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
                if (capture.WaveFormat.SampleRate != _outputFormat.SampleRate)
                {
                    sampleProvider = new WdlResamplingSampleProvider(sampleProvider, _outputFormat.SampleRate);
                }

                // –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–∞–Ω–∞–ª–æ–≤
                if (sampleProvider.WaveFormat.Channels == 1)
                {
                    sampleProvider = new MonoToStereoSampleProvider(sampleProvider);
                }
                else if (sampleProvider.WaveFormat.Channels > 2)
                {
                    // –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 –∫–∞–Ω–∞–ª–∞
                    sampleProvider = new MultiplexingSampleProvider(new[] { sampleProvider }, 2);
                }

                // –î–æ–±–∞–≤–ª—è–µ–º –≤ –º–∏–∫—à–µ—Ä
                _mixer.AddMixerInput(sampleProvider);

                // –ü–æ–¥–ø–∏—Å—ã–≤–∞–µ–º—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã–µ
                capture.DataAvailable += (s, e) =>
                {
                    if (e.BytesRecorded > 0 && !_isPaused)
                    {
                        buffer.AddSamples(e.Buffer, 0, e.BytesRecorded);
                    }
                };

                capture.RecordingStopped += (s, e) =>
                {
                    if (e.Exception != null)
                    {
                        AppLogger.LogError($"Capture –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Å –æ—à–∏–±–∫–æ–π: {e.Exception.Message}");
                    }
                };

                _captures.Add(capture);
                _buffers.Add(buffer);
            }
            catch (Exception ex)
            {
                AppLogger.LogWarning($"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {source.Name}: {ex.Message}");
            }
        }

        if (_captures.Count == 0)
            throw new InvalidOperationException("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫");

        // –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏
        _writer = new WaveFileWriter(outputPath, _outputFormat);
    }

    private void StartCapture()
    {
        _cts = new CancellationTokenSource();
        _isPaused = false;
        _stopwatch.Restart();

        // –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –∑–∞–ø–∏—Å–∏
        _recordingThread = new Thread(RecordingLoop)
        {
            IsBackground = true,
            Priority = ThreadPriority.Highest,
            Name = "AudioRecordingThread"
        };
        _recordingThread.Start();

        // –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ captures
        foreach (var capture in _captures)
        {
            capture.StartRecording();
        }

        UpdateState(RecordingState.Recording);
    }

    private void RecordingLoop()
    {
        // –†–∞–∑–º–µ—Ä —Ñ—Ä–µ–π–º–∞: 20ms (—Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å—é –∏ CPU)
        const int frameMs = 20;
        int samplesPerFrame = _outputFormat.SampleRate * 2 * frameMs / 1000; // stereo
        var floatBuffer = new float[samplesPerFrame];
        var byteBuffer = new byte[samplesPerFrame * 2]; // 16-bit

        var sw = Stopwatch.StartNew();
        long frameCount = 0;

        while (!_cts!.Token.IsCancellationRequested)
        {
            try
            {
                if (_isPaused)
                {
                    Thread.Sleep(10);
                    continue;
                }

                // –ß–∏—Ç–∞–µ–º –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                int samplesRead = _mixer!.Read(floatBuffer, 0, samplesPerFrame);

                if (samplesRead > 0 && _writer != null)
                {
                    // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º float ‚Üí 16-bit PCM —Å –∫–ª–∏–ø–ø–∏–Ω–≥–æ–º
                    for (int i = 0; i < samplesRead; i++)
                    {
                        float sample = Math.Clamp(floatBuffer[i], -1f, 1f);
                        short pcm = (short)(sample * 32767);
                        byteBuffer[i * 2] = (byte)(pcm & 0xFF);
                        byteBuffer[i * 2 + 1] = (byte)((pcm >> 8) & 0xFF);
                    }

                    _writer.Write(byteBuffer, 0, samplesRead * 2);
                }

                // –û–±–Ω–æ–≤–ª—è–µ–º UI –∫–∞–∂–¥—ã–µ 500ms
                frameCount++;
                if (frameCount % (500 / frameMs) == 0)
                {
                    UpdateState(RecordingState.Recording);
                }

                // –¢–æ—á–Ω—ã–π —Ç–∞–π–º–∏–Ω–≥: —Å–ø–∏–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ñ—Ä–µ–π–º–∞
                long targetMs = frameCount * frameMs;
                long sleepMs = targetMs - sw.ElapsedMilliseconds;
                if (sleepMs > 0)
                {
                    Thread.Sleep((int)sleepMs);
                }
            }
            catch (Exception ex)
            {
                AppLogger.LogError($"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –∑–∞–ø–∏—Å–∏: {ex.Message}");
                Thread.Sleep(10);
            }
        }
    }

    public Task StopRecordingAsync()
    {
        if (_currentInfo.State == RecordingState.Stopped)
            return Task.CompletedTask;

        return Task.Run(() =>
        {
            lock (_lock)
            {
                AppLogger.LogInfo("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...");

                // –°–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫—É
                _cts?.Cancel();

                // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ captures
                foreach (var capture in _captures)
                {
                    try { capture.StopRecording(); } catch { }
                }

                // –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –∑–∞–ø–∏—Å–∏
                _recordingThread?.Join(2000);

                _stopwatch.Stop();
                Cleanup();
                UpdateState(RecordingState.Stopped);

                AppLogger.LogInfo("–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞");
            }
        });
    }

    public Task PauseRecordingAsync()
    {
        if (_currentInfo.State != RecordingState.Recording)
            return Task.CompletedTask;

        _isPaused = true;
        _stopwatch.Stop();
        UpdateState(RecordingState.Paused);
        AppLogger.LogInfo("–ó–∞–ø–∏—Å—å –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞");
        return Task.CompletedTask;
    }

    public Task ResumeRecordingAsync()
    {
        if (_currentInfo.State != RecordingState.Paused)
            return Task.CompletedTask;

        _isPaused = false;
        _stopwatch.Start();
        UpdateState(RecordingState.Recording);
        AppLogger.LogInfo("–ó–∞–ø–∏—Å—å –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∞");
        return Task.CompletedTask;
    }

    public RecordingInfo GetCurrentRecordingInfo()
    {
        return _currentInfo with
        {
            Duration = _stopwatch.Elapsed,
            FileSizeBytes = _writer?.Length ?? 0
        };
    }

    private void UpdateState(RecordingState state)
    {
        _currentInfo = new RecordingInfo(
            state,
            _stopwatch.Elapsed,
            _writer?.Length ?? 0
        );
        RecordingStateChanged?.Invoke(this, _currentInfo);
    }

    private void Cleanup()
    {
        try { _writer?.Dispose(); } catch { }
        _writer = null;

        foreach (var capture in _captures)
        {
            try { capture.Dispose(); } catch { }
        }
        _captures.Clear();
        _buffers.Clear();

        _mixer = null;
        _cts?.Dispose();
        _cts = null;
        _recordingThread = null;
    }

    public void Dispose()
    {
        _cts?.Cancel();
        Cleanup();
        GC.SuppressFinalize(this);
    }
}
